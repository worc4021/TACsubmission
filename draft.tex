
%% bare_jrnl.tex
%% V1.4a
%% 2014/09/17
%% by Michael Shell
%% see http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8a or later) with an IEEE
%% journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_conf_compsoc.tex,
%%                    bare_jrnl_compsoc.tex, bare_jrnl_transmag.tex
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices and paper sizes can       ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[journal]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[journal]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/tex-archive/info/epslatex/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex

\usepackage{lpic}

\usepackage{xcolor}

% *** MATH PACKAGES ***
%
\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/


\usepackage{amsthm}


% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Do not use the stfloats baselinefloat ability as IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/dblfloatfix/




%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley, Jeff Goldberg and 
% Axel Sommerfeldt. This package may be useful when used in conjunction with 
% IEEEtran.cls'  captionsoff option. Some IEEE journals/societies require that
% submissions have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.4.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/endfloat/
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a 
% page by themselves.


\usepackage{amssymb,mathrsfs}

% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/url/
% Basically, \url{my_url_here}.

\usepackage[hidelinks]{hyperref}


\providecommand{\norm}[1]{\left\|#1\right\|}
\providecommand{\abs}[1]{\left|#1\right|}
\providecommand{\span}{\text{span}}
\providecommand{\conv}{\text{conv}}
\providecommand{\rk}[1]{\text{rank}\left(#1\right)}

\newcommand*{\Resize}[1]{\resizebox{\columnwidth}{!}{$#1$}}

\newcounter{thmcount}
\renewcommand{\thethmcount}{\arabic{thmcount}}
\renewcommand{\theequation}{\arabic{section}.\arabic{equation}}
\renewcommand{\thefigure}{\arabic{section}.\arabic{figure}}


\newtheorem{thm}[thmcount]{Theorem}
\newtheorem{cor}[thmcount]{Corollary}

\theoremstyle{remark}
\newtheorem{rem}[thmcount]{Remark}

\theoremstyle{definition}
\newtheorem{defi}[thmcount]{Definition}

\DeclareFontFamily{U}{mathx}{\hyphenchar\font45}
\DeclareFontShape{U}{mathx}{m}{n}{
      <5> <6> <7> <8> <9> <10> gen * mathx
      <10.95> mathx10 <12> <14.4> <17.28> <20.74> <24.88> mathx12
      }{}
\DeclareSymbolFont{mathx}{U}{mathx}{m}{n}
\DeclareFontSubstitution{U}{mathx}{m}{n}
\DeclareMathSymbol{\temp}{\mathbin}{mathx}{'341}
\newcommand{\bigominus}{\raisebox{10pt}{$\temp$}}


% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{State and Input Dependent Disturbances in Min-Max Model Predictive Control}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{Rainer~M.~Schaich,~\IEEEmembership{Student Member,~IEEE,}
        Mark~Cannon
\thanks{The authors are with the Department of Engineering Science, University of
Oxford, Parks Road, Oxford, OX1~3PJ, e-mail: rainer.schaich@eng.ox.ac.uk, 
mark.cannon@eng.ox.ac.uk}% <-this % stops a space
%\thanks{Manuscript received April 19, 2005; revised September 17, 2014.}
}

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers
\markboth{IEEE TRANSACTIONS ON AUTOMATIC CONTROL}%
{Schaich \MakeLowercase{\textit{et al.}}: \thetitle}
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.




% If you want to put a publisher's ID mark on the page you can do it like
% this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2014 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.



% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
The abstract goes here.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
IEEEtran, journal, \LaTeX, paper, template.
\end{IEEEkeywords}






% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\def\genmat{\Xi} \def\genvec{\xi}

\section{Introduction}
% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps.
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.

Robust model predictive control (RMPC) is a control strategy for uncertain systems that optimises a 
performance objective for all possible realisations of model uncertainty.
%
First introduced in~\cite{Witsenhausen:1968}, the min-max RMPC problem is formulated as a sequence of games in which an adversary maximises the effect of model disturbances on a performance objective, and the controller solves the optimal
control problem for the resulting worst-case system.
%
We discuss the \emph{closed-loop setup} where, at each stage of a prediction horizon, the disturbance input maximizes the sum of the stage cost and the cost-to-go, and the control input minimises this cost so that the controller reacts to the worst-case disturbance at each stage.
%
The closed-loop setup includes, as a special case, the \emph{open-loop setup} in which the disturbance is allowed to perturb the 
entire trajectory before the controller is allowed to react, since this can be understood as a closed loop setup (with a horizon length of one) applied to a lifted system.
%

This paper considers the use of parametrised sets to bound model uncertainty. By allowing the bounds on model uncertainty to depend explicitly on the model state and control input we obtain a generalised framework for RMPC in which linearisation errors and multiplicative uncertainties can be modelled as additive disturbances.
%
General parametrised disturbance bounding sets were used in~\cite{Rakovic03,Rakovic06}; however, here we focus exclusively on problem formulations that lead to convex-concave min-max control problems.
% 
The paper's main contributions are to develop
%extends~\cite{Schaich:CDC:2015} by developing 
the analytical and computational tools that are needed to characterise and determine convex invariant and controllable sets for systems with parametrised uncertainty sets, and to employ these sets in a closed loop RMPC strategy. To this end, we provide necessary and sufficient conditions for the property, introduced in~\cite{Schaich:CDC:2015}, of \emph{parametric convexity}. We show that this condition is both necessary and sufficient to ensure that the corresponding robustly invariant and controllable sets are convex.

A major challenge in RMPC is to guarantee feasibility of the control problem for all possible uncertainties in 
presence of state constraints.
%
This can be achieved by introducing additional constraints into the problem that force the state at the end of the horizon to lie in a set that is feasible and invariant for all possible realisations of uncertainty under a given feedback law; the largest such set, 
the so-called \emph{maximal robust positively invariant} (MRPI) set, is often used for this purpose.
%
The concept of MRPI sets and their analytical properties were introduced in the literature (e.g.~\cite{Bertsekas:1971,Glover:1971}) shortly after robust model predictive control was originally proposed. However algorithms for numerically 
computing MRPI sets were not developed until more than two decades later~\cite{Blanchini:1994,DeSantis:1994,Kolmanovsky:1998}.
% earlier algorithms either failed to ensure finite determinability
% of the MRPI set (see e.g.~\cite{Blanchini:1990}), 
% or were not guaranteed to produce the maximal RPI set (e.g.~\cite{Blanchini:1991}).
%
This paper builds on the work of~\cite{Kolmanovsky:1998,Rakovic06} by proposing an iterative procedure for computing the MRPI set for the case of parametrically convex state and input dependent disturbance sets. We show that, under mild assumptions, this procedure determines the MRPI set in a finite number of iterations, and we provide a bound on the number of iterations required.

The current paper also develops an online implementation of closed loop min-max RMPC that allows the bounds on model uncertainty to depend on the model state and control input.
%
Several methods are available to solve RMPC problems with fixed disturbance bounds. For the case of unknown additive disturbances, 
a scenario-based approach is proposed in~\cite{Scokaert:1998} for the online solution of min-max RMPC problems. However, the computational complexity of this approach grows exponentially with the length of the horizon. 
%
A parametrisation of predicted feedback laws proposed in~\cite{Rakovic:2012} reduces the RMPC problem to a single linear 
program to be solved online, but although this is a closed loop strategy, the parametrisation is in general 
suboptimal. 
%
The Explicit RMPC algorithms~\cite{Bemporad:2003,Diehl:2004} optimise the worst case predicted performance for each admissible model state offline and
use results from multi-parametric programming to parametrise the optimal control law as a piecewise affine function of the
state.
%
However, this requires extensive offline computation and becomes impractical for a high-dimensional state space.
%
In this paper we use an active set approach based on that presented in~\cite{Buerger:ACC,Buerger:IJRNC} for the case of additive disturbances confined to a fixed set and we extend the approach for parametrised sets that was introduced in~\cite{Schaich:NMPC:2015} by considering the case of degenerate constraints.
%
In a similar manner to explicit RMPC algorithms, we use multi-parametric programming to obtain solutions efficiently
for a given active set, however, we avoid an exploration of the entire feasible set of states but rather solve online for the current state only.
%
Our approach uses a line search to update the set of active constraints, thus generating
the solution of the RMPC problem online in an efficient manner.

The paper is structured as follows, in section~\ref{sec:problem:statement} we present the RMPC problem under consideration
and define the constraint sets for the model uncertainty in terms of state and input dependent disturbance sets.
%
The properties of parametrised sets are then considered in section~\ref{sec:p:convex:sets}, in particular we discuss
parametric convexity and its characterisation in section~\ref{ssec:properties:of:p:convex:maps}, and its use in the computation of MRPI sets, which is presented in section~\ref{ssec:MRPI:sets}.
%
To illustrate how state and input dependent disturbances can be used to account for nonlinearities and 
calculate the MRPI set we present an example in section~\ref{sec:example:I}.
%
The solver we present here relies entirely on a recursive use of multi-parametric programming techniques, 
which are presented in section~\ref{ssec:recursive:mpQP} for a given active set, the active set is then
updated using a line search which is described in subsection~\ref{ssec:line:search}. In order to account for the 
degeneracy that can occur in the optimisation, we consider the case of degenerate problems in subsection~\ref{ssec:degeneracy}.
%
In section~\ref{sec:solving:min:max:programs} we translate the general formulation of section~\ref{sec:recursive:mpQP:via:line:search}
to the problem presented in section~\ref{sec:problem:statement}, and section~\ref{sec:complexity}
deals with the complexity of the proposed algorithm.
%
We revisit the example system presented in section~\ref{sec:example:I} to illustrate the proposed RMPC
algorithm in section~\ref{sec:example:II}.
%
Section~\ref{sec:conclusion} provides brief conclusions.

\emph{Notation:} Throughout this paper we denote 
the image of a set $\mathcal C\subseteq X$ under the map $f:X\mapsto Y$ as $f\vert_{\mathcal C} = \{y\in Y:\exists x\in\mathcal C,\;y=f(x)\}$. 
%
Given a collection of row-vectors $a_i$ and scalars $b_i$ for $i\in\{1,\ldots,m\}$, we denote as ${\bf{a}}_{\mathcal I}$ and
${\bf{b}}_{\mathcal I}$ the matrix and vector, respectively, with rows $a_i$ and $b_i$ for all indices $i$ in the index set $\mathcal I\subseteq\{1,\dots,m\}$.

%To represent the facets of a polytope defined by intersection of the half spaces $\{x : a_i x \leq b_i\}$ for $i\in\{1,\dots,m\}$, we denote as ${\bf{a}}_{\mathcal I}$ and ${\bf{b}}_{\mathcal I}$ the matrix and vector, respectively, with rows $a_i$ and $b_i$ for all indices in the index set $i\in\mathcal I\subseteq\{1,\dots,m\}$.


\section{Problem statement}\label{sec:problem:statement}
%
Throughout this paper we aim to solve the robust model predictive control problem
%
\begin{subequations}\label{seq:general:problem:statement}
\begin{equation}\label{eq:min:max:objective}
  J^\ast_m(x) = \min_u \max_{w,x^+} J(x,u,w) + 
  J^\ast_{m-1}(x^+)
\end{equation}
%
with $J(x,u,w) = \frac{1}{2}\left(x^T Qx + u^TRu - \gamma^2 w^T w\right)$,
%
subject to the system dynamics
%
\begin{equation}\label{eq:system:dynamics}
  x^+ = Ax + Bu + Dw,
\end{equation}
%
the input constraints
%
\begin{equation}\label{eq:general:input:constraints}
  u\in U
\end{equation}
%
\emph{state and input dependent} disturbance constraints
%
\begin{equation}\label{eq:disturbance:constraints}
  w\in\mathcal W(x,u),
\end{equation}
%
and state constraints
%
\begin{equation}\label{eq:general:state:constraints}
  x\in\mathcal X
\end{equation}
\end{subequations}
%
We assume that $Q\geq0$ and $R>0$ are semi-positive and positive definite constant matrices respectively,
the matrices $A,B,D$ are also assumed to be deterministic and known.
%
Since we require guarantees of stability and feasibility in presence of disturbances arbitrary state constraints
like~\eqref{eq:general:state:constraints} can not be robustly satisfied~\cite{Bertsekas:1971}, instead specially designed
ones are used.
%
Recursively defined sets are used to guarantee that the terminal state lies in the 
\emph{maximal robust positive invariant} (MRPI) set~$\mathcal X^\infty\subseteq\mathcal X$ 
(see e.g.~\cite{blanchini:2007}), i.e. the largest set satisfying
%
\begin{equation}\label{eq:definition:MRPI:set}
  \mathcal X^\infty = \{x\in\mathcal X: \Psi x + v \in\mathcal X^\infty\;\forall v\in\mathcal V(x)\}.
\end{equation}
%
The MRPI set~\eqref{eq:definition:MRPI:set} is defined for $\Psi=A+BK$ and $\mathcal V(x) = D\mathcal W(x,Kx)$,
with a fixed feedback controller $u = Kx$.
%
Starting from the MRPI set~$\mathcal X_0=\mathcal X^\infty$ we recursively define
%
\begin{equation}\label{eq:stage:constraints:in:x:and:u}
  \mathcal Z_i = \{(x,u)\in\mathcal X\times U: Ax + Bu + Dw \in\mathcal X_{i-1}\;\forall w\in\mathcal W(x,u)\}
\end{equation}
%
and its projection
%
\begin{equation}
  \mathcal X_i = \{x:\exists u\in U\; (x,u)\in\mathcal Z_i\}.
\end{equation}
%
The state constraint~\eqref{eq:general:state:constraints} and input constraint~\eqref{eq:general:input:constraints}
are then replaced by $(x,u)\in\mathcal Z_m$.
%
To initialise the cost-to-go we use $J_0^\ast(x) = \frac{1}{2}x^T P_0x$, which is designed in combination with the feedback 
controller~$K$ as the optimal unconstrained solution to~\eqref{seq:general:problem:statement}, i.e. they satisfy
$J_0^\ast(x) - J_0^\ast(x^+)\geq J(x,Kx,w)$, see e.g.~\cite{Boyd:94}.
%
Both input and state constraint sets are assumed polyhedral $U=\{u:F_iu\leq1\forall i\in\mathcal I_U\}$ and $\mathcal X = 
\{x:\genmat_i x\leq \genvec_i\forall i\in\mathcal I_{\mathcal X}\}$.
%
For the disturbance set~\eqref{eq:disturbance:constraints} we assume that there exists a piecewise affine representation
%
\begin{equation}\label{eq:definition:disturbance:set:explicit}
  \mathcal W(x,u) = \{w:G_i w\leq\max_{k}\{H_{i,k}^x x + H_{i,k}^u + h_{i,k}\}\forall i\in\mathcal I_{\mathcal W}\}.
\end{equation}
%
The properties of such sets will be discussed in section~\ref{sec:p:convex:sets}.
%
%
%
%
\section{Parametrically Convex Sets}\label{sec:p:convex:sets}
In this section we discuss \emph{parametric convexity}, an attribute of sets valued maps 
(so called point-to-set maps, see e.g.~\cite{Hogan:1973}) we exploit later on to prove 
convexity of a generalised Pontryagin difference in order to 
%
\begin{defi}[Parametric Convexity]\label{def:parametric:convexity}
  Let $X\subseteq\mathbb R^d, Y\subseteq\mathbb R^n$, let $\mathscr P(Y)$ 
  denote the power set of $Y$, 
  and $\mathcal W:X\rightarrow \mathscr P(Y)$, $X\ni p\mapsto \mathcal W(p)
  \subset Y$ be a continuous point-to-set map. The map $\mathcal W$ is called 
  \emph{parametrically convex} if it satisfies
%
  \begin{equation}\label{eq:def:parametrically:convex}
  \mathcal W(\lambda p_1 + (1-\lambda)p_2)\subseteq\lambda \mathcal W(p_1) \oplus (1-\lambda) \mathcal W(p_2)
  \end{equation}
%
  for all $p_1,p_2\in X$ and $\lambda\in[0,1]$.
\end{defi}
%
Notice that Definition~\ref{def:parametric:convexity} does not require convexity of~$\mathcal W(p)$ for all
$p\in X$, we will however only treat maps~$\mathcal W$ for which $\mathcal W(p)$ is convex.


\subsection{Properties of Parametrically Convex Maps}\label{ssec:properties:of:p:convex:maps}
%
In this subsection we introduce an equivalent characterisation of parametric 
convexity that will yield some insight on the topological 
definition~\ref{def:parametric:convexity}, for this we characterise parametric
convexity in terms of the graph of the point-to-set map.
%
\begin{defi}\label{def:graph:of:map}
Let $\mathcal W:X\rightarrow \mathscr P(Y)$ be a continuous point-to-set map
such that $\mathcal W(p)$ is convex for all $p\in X$, then 
%
\[
  \mathscr G(\mathcal W) = \{(p,x) \in\mathbb R^{d+n}: x\in\mathcal W(p)\},
\]
%
denotes the \emph{graph} of $\mathcal W$,
%
\[
  \text{int}(\mathscr G(\mathcal W)) = \{(p,x) \in\mathbb R^{d+n}: \forall d\in\mathbb R^n\;\exists 
  \epsilon>0 : x+\epsilon d\in \mathcal W(p)\}
\]
%
its \emph{interior} and
%
\[
  \partial \mathscr G(\mathcal W) = \mathscr G(\mathcal W)\setminus \textup{int}(\mathscr G(\mathcal W))
\]
%
its \emph{boundary}. 
%
The \emph{orientation cone} for all $(p,x)\in\partial\mathscr G(\mathcal W)$
is given by
%
\[
  \mathcal N\mathcal W(p,x) = \{d\in\mathbb R^n: x+\epsilon d \not\in \mathcal W(p)\; \forall \epsilon>0\}.
\]
\end{defi}
%
\begin{rem}
%
Notice, that definition~\ref{def:graph:of:map} is given in terms of the \emph{set variable} $x$ rather than \emph{graph variable} $(p,x)$.
%
Furthermore, notice that the orientation cone contains all directions that 
point out of the set, hence all linear combinations thereof.
%
\end{rem}
%
We state the central theorem to connect parametric convexity of a set valued 
map $\mathcal W$ with properties of its graph $\mathscr G(\mathcal W)$.
%
\begin{thm}\label{thm:p:convexity:graph}
The map $\mathcal W$ is parametrically convex iff for all $(p_1,x_1),(p_2,x_2)\in\partial\mathscr G(\mathcal W)$
with $\mathcal N\mathcal W(p_1,x_1)\cap\mathcal N\mathcal W(p_2,x_2)\neq\emptyset$ and $p_1\neq p_2$ 
%
\begin{equation}\label{eq:graph:def:p:convexity}
\lambda (p_1,x_1) + (1-\lambda) (p_2,x_2) \not\in\textup{int} (\mathscr G(\mathcal W))
\end{equation}
%
holds for all $\lambda\in(0,1)$.
%
\end{thm}
%
\begin{proof}
%
Assume~\eqref{eq:graph:def:p:convexity} holds for $(p_1,x_1),(p_2,x_2)\in\partial\mathscr G(\mathcal W)$.
%
Then the Minkowski functional (see e.g.~\cite{Rudin:91}) yields $\mu_{\mathscr G(\mathcal W)}(\mathcal W(\lambda p_1 + (1-\lambda)p_2),
\lambda x_1+(1-\lambda)x_2)\geq1$,
i.e. all interpolation points lie either on the boundary or outside the set $\mathcal W(\lambda p_1+(1-\lambda)p_2)$
therefore the set of all possible interpolation points 
%
\[
\begin{split}
  \lambda \mathcal W(p_1)\oplus (1-\lambda)\mathcal W(p_2) = \{x:x=\lambda x_1 + (1-\lambda) x_2 \wedge\\ x_1\in\mathcal 
  W(p_1) \wedge x_2\in\mathcal W(p_2)\}
\end{split}
\]
%
contains the set $\mathcal W(\lambda p_1 + (1-\lambda)p_2)$.
%
Now assume $\mathcal W$ is parametrically convex but~\eqref{eq:graph:def:p:convexity} is not satisfied for 
some $(p_1,x_1),(p_2,x_2)\in\partial\mathscr G(\mathcal W)$ with $\mathcal N\mathcal W(p_1,x_1)\cap\mathcal 
N\mathcal W(p_2,x_2)\neq\emptyset$, i.e. $\lambda x_1 + (1-\lambda)x_2\in\text{int}(\mathcal W(\lambda p_1 + 
(1-\lambda)p_2)$.
%
This implies that a full dimensional ball $B_\epsilon(x ) = \{y:\| 
x-y\|<\epsilon\}$
is contained in $\mathcal W(\lambda p_1 + (1-\lambda)p_2)$, i.e. $B_\epsilon(\lambda x_1 + (1-\lambda)x_2 )\subset
\mathcal W(\lambda p_1 + (1-\lambda)p_2)$ for some $\epsilon>0$.
%
Since $\mathcal N\mathcal W(p_1,x_1)\cap\mathcal N\mathcal W(p_2,x_2)\neq\emptyset$, there exist directions 
$d\in\mathcal N\mathcal W(p_1,x_1)\cap\mathcal N\mathcal W(p_2,x_2)$ which can not be represented as $d=\lambda d_1+
(1-\lambda)d_2$ with $x_1 + \epsilon d_1\in\mathcal W(p_1)$ and $x_2  + \epsilon d_2\in\mathcal W(p_2)$, however since $B_\epsilon$ is full dimensional
all directions exist, $x+\epsilon d\in\mathcal W(\lambda p_1 + (1-\lambda)p_2)$.
%
Hence, $\mathcal W$ can not be parametrically convex.
\end{proof}
%
\begin{rem}
Notice that condition~\eqref{eq:graph:def:p:convexity} is a non-convexity condition on the graph $\mathscr G(\mathcal W)$.
%
If $\mathscr G(\mathcal W)$ is strictly convex anywhere~\eqref{eq:graph:def:p:convexity} is violated and 
$\mathcal W$ can not be parametrically convex.
\end{rem}
%
\begin{cor}
%
Let $\mathcal W(p):=\{x\in\mathbb R^n: r(p,x)\leq0\}$ define a point-to-set
map with a continuous function 
$r: \mathbb R^d \times\mathbb R^n \rightarrow \mathbb R,(p,x)\mapsto r(p,x)$, 
then $\mathcal W$ is parametrically
convex iff the function $r$ is concave in $p\in\mathbb R^d$ and convex in $x\in
\mathbb R^n$.
%
\end{cor}
%
\begin{proof}
The convexity in $x\in\mathbb R^n$ is required to satisfy the requirement that $\mathcal W(p)$ is convex
for all fixed values of $p\in\mathbb R^d$. 
%
Assume that for some region $\Omega\subset\mathbb R^d$ the function $r(\cdot,x)$ is non-concave (i.e. 
strictly convex), any convex subset $\mathcal C\subseteq\Omega$ will hence be such that $\mathscr 
G(\mathcal W)\vert_{\mathcal C}$ is a convex set.
%
In particular all lines between all $(p_1,x_1),(p_2,x_2)\in \partial\mathscr G(\mathcal W)\vert_{\mathcal C}$ will satisfy
$\lambda (p_1,x_1) + (1-\lambda) (p_2,x_2) \in\textup{int} (\mathscr G(\mathcal W))\vert_{\mathcal C}$ since
$\mathscr G(\mathcal W)\vert_{\mathcal C}$ is strictly convex in $p$.
%
This implies that $r(\cdot,x)$ can not be non-concave in any non-trivial set $\Omega\subseteq\mathbb R^d$ and still
be parametrically convex.
\end{proof}
%
\begin{cor}\label{thm:polytopic:set:not:p:convex}
The polytopic parametric set valued map $\mathcal W(p):=\{x: a_i x + b_i p\leq c_i \forall i\leq m\}$ is not parametrically convex for 
any non-trivial matrix $B$.
\end{cor}
%
\begin{proof}
The graph $\mathscr G(\mathcal W)$ is given by
%
\begin{equation*}
	\mathscr G(\mathcal W) = \{(p,x):a_i x + b_i p\leq c_i \forall i\leq m\}
\end{equation*}
%
and hence is a convex set and violates Theorem~\ref{thm:p:convexity:graph}.
\end{proof}
%
\begin{cor}\label{thm:p:convexity:PWA:set:constant:num:verts}
The non-degenerate piecewise affine polytopic parametric point-to-set valued map 
%
\begin{equation}\label{eq:definition:PWA:polytopic:set:general}
  \mathcal W(p) := \left\{x: a_i x \leq \max_{k\leq l}\{b_{i,k} + c_{i,k}p\},i\leq m\right\}
\end{equation}
%
is parametrically convex iff the number of vertices $v_\kappa(p)$ and rays $r_\eta(p)$ is constant.
\end{cor}
%
\begin{proof}
For clarity this proof is divided in 3 parts:
\begin{enumerate}
\item Notice that $h_i(p) = \max_{k\leq l} \{b_{i,k} + c_{i,k}p\}$ is a multi-parametric linear program (mpLP),
its solution is a piecewise affine function $h_i(p) = b_{i,k^\ast_i} + c_{i,k^\ast_i}p$ where $k^\ast_i(p)$ is constant
inside a polytopic complex, see e.g.~\cite{spjotvold:2005}.
%
That means that there exists a finite polyhedral partitioning $\mathbb R^d = \bigcup_{j\leq t} \mathcal P_j$ with convex polyhedra 
$\mathcal P_j$ such that ${\bf{k}}^\ast\vert_{\mathcal P_j} = (k_1^\ast,\dots,k_m^\ast) = const$.
%
A standard degeneracy assumption is that in neighbouring partitions ${\bf{k}}^\ast\vert_{\mathcal P_{j_1}}$ and 
${\bf{k}}^\ast\vert_{\mathcal P_{j_2}}$ differ in exactly one element.
%
This partitioning implies that the graph $\mathscr G(\mathcal W)$ is given as a finite union of polyhedra
%
\begin{equation*}
  \mathscr G(\mathcal W) = \bigcup_{j\leq t} \left\{x: a_i x \leq b_{i,k_i^\ast} + c_{i,k_i^\ast}p,i\leq m
  \right\}\bigr\vert_{\mathcal P_{j}}
\end{equation*}
%
But this implies that if the number of vertices or rays changes inside any partition $\mathcal P_j$ then $\mathscr
G(\mathcal W)\vert_{\mathcal P_j}$ is a strictly convex polyhedron and corollary~\ref{thm:polytopic:set:not:p:convex} applies.
%
\item Our attention hence is concentrated to the boundaries of the partitions $\mathcal P_j$.
%
These are the points $\mathcal P_{j_1} \cap \mathcal P_{j_2}$ where some mpLP changes its solution, i.e. 
$\left(b_{i,k_i^\ast} + c_{i,k_{j_1}^\ast} p\right)\big\vert_{\mathcal P_{j_1}} = 
\left(b_{i,k_{j_2}^\ast} + c_{i,k_{j_2}^\ast} p\right)\big\vert_{\mathcal P_{j_2}}$.
%
Notice that a vertex $v_\kappa(p)$ is given by \emph{active} and \emph{inactive} inequalities, i.e. $\mathcal A_\kappa(p)$ and
$\mathcal I_\kappa(p) = \{1,\dots,m\}\setminus\mathcal A_\kappa(p)$ respectively.
%
\begin{equation*}\begin{split}
  a_i v_\kappa(p) &= b_{i,k_i^\ast} + c_{i,k_i^\ast} p \quad\forall i\in\mathcal A_\kappa(p)\\
  a_i v_\kappa(p) &< b_{i,k_i^\ast} + c_{i,k_i^\ast} p \quad\forall i\in\mathcal I_\kappa(p)
\end{split}\end{equation*}
%
In order for the number of vertices to change, there must be a hyperplane $fp=g$, such that the number of vertices for $fp<g$ is 
$N$ and for $fp>g$ is at least $N+1$.
%
It follows from the previous discussion that $\{p:fp=g\} = \textup{aff}\{\mathcal P_{j_1}\cap\mathcal P_{j_2}\}$ for some $j_1\neq j_2$.
%
For vertices $v_{\kappa_1}(p)$ and $v_{\kappa_2}(p)$ to merge the index sets $\mathcal A_{\kappa_1}(p)$ and 
$\mathcal A_{\kappa_2}(p)$ have to differ in only one 
element, i.e. $\mathcal A_{\kappa_1}(p) = \mathcal J\cup \{s\}$ and $\mathcal A_{\kappa_2}(p) = \mathcal J\cup\{u\}$ for $fp>g$.
%
Furthermore, for $p$ with $fp\leq g$ we have $v_{\kappa_1}(p)=v_{\kappa_2}(p)$, this implies $\mathcal A_{\kappa_1}(p) = 
\mathcal A_{\kappa_2}(p)$.
%
Since only one alteration of the active index set is considered (due to non-degeneracy assumptions), the active set 
$\mathcal A_{\kappa_1}(p) = \mathcal A_{\kappa_2}(p) = \mathcal J \cup \{s,u\}$.
%
Hence on the hyperplane $fp=g$ both, the maximising index ${\bf{k}}^\ast(p)$ and the active index sets $\mathcal A_{\kappa_1}(p)$ 
and $\mathcal A_{\kappa_2}(p)$ change, which is means the problem is degenerate.
%
\item In order for the degenerate graph $\mathscr G(\mathcal W)$ to be parametrically convex the overdetermined 
vertex $v_{\kappa_1}(p)=v_{\kappa_2}(p)$ have to be identical, in particular their dependence on $p$ has to be identical.
%
This can be expressed with the implicit function theorem:
%
\begin{equation*}\begin{split}
  \frac{d}{dp}\left(  {\bf{a}}_{\mathcal J\cup \{s\}} v_{\kappa_1}(p) - {\bf{b}}_{\mathcal J\cup \{s\}} - 
  {\bf{c}}_{\mathcal J\cup \{s\},{\bf{k}}^\ast} p\right) &= 0\\
  \frac{d}{dp}\left(  {\bf{a}}_{\mathcal J\cup \{u\}} v_{\kappa_2}(p) - {\bf{b}}_{\mathcal J\cup \{u\}} - 
  {\bf{c}}_{\mathcal J\cup \{u\},{\bf{k}}^\ast} p\right) &= 0
\end{split}\end{equation*}
%
which leads to 
%
\begin{equation*}\begin{split}
  {\bf{a}}_{\mathcal J\cup \{s\}} \frac{dv_{\kappa}}{dp} &= {\bf{c}}_{\mathcal J\cup \{s\},{\bf{k}}^\ast}\\
  {\bf{c}}_{\mathcal J\cup \{u\}} \frac{dv_{\kappa}}{dp} &= {\bf{c}}_{\mathcal J\cup \{u\},{\bf{k}}^\ast}
\end{split}\end{equation*}
%
since we can assume that the inequalities are non-redundant for some right hand side, we obtain that 
%
\begin{equation}\label{eq:derivative:condition:on:index:sets}
  \frac{dv_\kappa}{dp} = {\bf{a}}_{\mathcal J\cup \{s\}}^{-1}{\bf{c}}_{\mathcal J\cup \{s\},{\bf{k}}^\ast} = 
  {\bf{a}}_{\mathcal J\cup \{u\}}^{-1}{\bf{c}}_{\mathcal J\cup \{u\},{\bf{k}}^\ast}
\end{equation}
%
has to hold for the degenerate graph to remain parametrically convex.
%
Notice that~\eqref{eq:derivative:condition:on:index:sets} is again a degenerate condition, since arbitrarily small perturbations
will produce different behaviour.
\end{enumerate}
\end{proof}
%
\begin{rem}
Corollary~\ref{thm:p:convexity:PWA:set:constant:num:verts} is essential for numerical evaluation, as it can be reformulated to:
%
The set valued map defined by~\eqref{eq:definition:PWA:polytopic:set:general} is non-degenerate and parametrically convex iff 
it has a constant number of vertices throughout the parameter space~$X$.
%
Since the map is continuous it is sufficient to verify this at the vertices of the parameter space.
%
\end{rem}
%
In order to determine MRPI sets we need to be able to calculate the Pontryagin difference between sets, hence we introduce
the following.
%
\begin{defi}[Parametric Pontryagin Difference]\label{def:parametric:pontryagin:difference}
  Let $S\subseteq X$ and let $\mathcal W:X\to\mathscr P(X)$ be a continuous point-to-set map such that
  $\mathcal W(p)$ is convex for all $p\in X$, then the \emph{parametric Pontryagin difference} 
  $S\ominus \mathcal W(S)$ is 
%
  \begin{equation}\label{eq:definition:parametric:pontryagin:difference}
    S\ominus \mathcal W(S) = \left\{x\in X: \{x\} \oplus \mathcal W(x)\subseteq S\right\},
  \end{equation}
%
  where $\mathcal W(S)$ denotes the image of $S$ under the map $\mathcal W$. 
\end{defi}
%
For the parametric Pontryagin difference of a convex set and a parametrically convex map we 
have the following result.
%
\begin{thm}\label{thm:convexity:of:pontryagin:difference}
  Let $S\subseteq X$ be a convex set and let $\mathcal W:X\rightarrow\mathscr P(X)$ be a parametrically convex point-to-set
  map such that $\mathcal W(p)$ is convex for all $p\in X$, then $S\ominus \mathcal W(S)$ is convex.
\end{thm}
%
\begin{proof}
To prove the convexity of $ Z :=  S\ominus \mathcal W( S)$ we pick any $z_1,z_2\in Z$, then
by definition of the parametric Pontryagin difference, we have
%
\begin{equation}
  \{z_i\} \oplus \mathcal W(z_i) \subseteq S,\; i=1,2.
\end{equation}
%
To see that $ Z$ is convex we show that line segments between
all possible $z_1$ and $z_2$ are subsets of $ Z$, i.e.~for all $\lambda \in [0,1]$,
\begin{equation}
\begin{aligned}
  \{ \lambda z_1 + (1-&\lambda)z_2
  \}\oplus \mathcal W\left( \lambda z_1 + (1-\lambda)z_2\right)\\
  \subseteq&\left\{ \lambda z_1 + (1-\lambda)z_2
  \right\}\oplus \lambda \mathcal W(z_1) \oplus (1-\lambda)
  \mathcal W(z_2)\\
  \subseteq &\lambda\underbrace{(\{z_1\}\oplus \mathcal W(z_1))}_{\subseteq S}\oplus
  (1-\lambda)\underbrace{(\{z_2\}\oplus \mathcal W(z_2))}_{\subseteq S}\\
  \subseteq& Z
\end{aligned}
\end{equation}
%
where the last inclusion follows from the convexity of $\mathcal S$.
\end{proof}
%
Theorem~\ref{thm:convexity:of:pontryagin:difference} only gives us the convexity of the parametric
Pontryagin difference, in the following we will see that the parametric Pontryagin difference between
a polyhedral set and a piecewise affine polytopic parametric set is polyhedral itself.
%
%
%
%
%
%
\subsection{Maximal Robust Positive Invariant Sets}\label{ssec:MRPI:sets}
%
In this section we describe an iterative algorithm to compute the MRPI set~\eqref{eq:definition:MRPI:set}
for a linear system~$x^+=\Psi x + v$ subject to disturbance $v\in\mathcal V(x)$ where $\mathcal V(x)$ is 
a piecewise affine parametrically convex point-to-set map defined 
like~\eqref{eq:definition:PWA:polytopic:set:general}.
%
We assume (without loss of generality) that the set $\mathcal V(x)$ is pointwise compact and polytopic 
for finite $x\in\mathcal X_0$ and can hence be represented as the 
convex hull of its vertices $\mathcal V(x) = \conv\{v_i(x)\}$. 
%
Since ${\mathcal{V}}(x)$ has a piecewise affine dependence on $x$ the vertices $v_i(x)$ are also piecewise 
affine in $x$.
%
The set $\mathcal X^\infty$ as defined in~\eqref{eq:definition:MRPI:set} is required to satisfy $\Psi x + 
v\in\mathcal X^\infty$ for all~$x\in\mathcal X^\infty$ and $v\in\mathcal V(x)$. 
%
To compute the MRPI set we start from the given state constraint set $\mathcal X_0=\mathcal X$
%
\[
\mathcal X_0 = \{x:\;\genmat_{0,i}x\leq \genvec_{0,i}\,\forall i\in\mathcal I_0\}
\]
%
and recursively \emph{cut off} points that cannot satisfy the invariance condition~\eqref{eq:definition:MRPI:set}
by iteratively introducing constraints that exclude all points for which the successor state can lie outside 
$\mathcal X_0$. 
%
The first iteration enforces the constraint:
%
\[
\begin{split}
  &\genmat_{0,i}(\Psi x + v)\overset{!}{\leq}\genvec_{0,i}\;\forall v\in\conv\{v_i(x)\}\\
  &\genmat_{0,i}\Psi x + \max_{v\in\mathcal V(x)} \genmat_{0,i} v \leq \genvec_{0,i}\\
  &\genmat_{0,i}\Psi x + \underbrace{\max_{j} \genmat_{0,i} v_j(x)}_{=v_{0,i}^\ast(x)} \leq \genvec_{0,i}.
\end{split}
\]
%
for each $i\in \mathcal I_0$.
%
Here $v_{0,i}^\ast(x)$ is not necessarily given by a unique maximiser, but is the solution of a multi-parametric 
linear program and hence is given by a vertex $v_i(x)$ of $\mathcal V(x)$ for all $x$ on that facet.
%
Since each vertex is a piece-wise affine function of $x$, the maximum $v_{0,i}^\ast(x)$ is also piece-wise affine
so the set $\mathcal X_1=\mathcal X_0 \cap \{x:\genmat_{0,i}\Psi x + v_{0,i}^\ast(x) \leq 
\genvec_{0,i}\forall i\in\mathcal I_0\}$
has representation $\mathcal X_1 = \{x:\genmat_{1,i}x\leq\genvec_{1,i}\,\forall i\in\mathcal I_1\}$.
%
The next iterate is defined by
%
\begin{align*}
  \mathcal X_2 &= \mathcal X_1 \cap \\ &\{x:\genmat_{0,i}\Psi(\Psi x + v) + v_{0,i}^\ast(x)\leq\genvec_{0,i}\,
  \forall i\in\mathcal I_0,v\in\mathcal V(x)\}\\
  &= \mathcal X_1 \cap \{x: \genmat_{0,i}\Psi^2 x + v_{1,i}^\ast(x) + v_{0,i}^\ast(x)\leq\genvec_{0,i}\,\forall 
  i\in\mathcal I_0\}
\end{align*}
%
and at the $(k+1)$st iteration we have
%
\[
  \mathcal X_{k+1} = \mathcal X_k\cap \{x:\genmat_{0,i}\Psi^k x + \sum_{l=1}^{k-1}v_{l,i}^\ast(x)
  \leq\genvec_{0,i}\,\forall i\in\mathcal I_0\},
\]
%
where 
%
\[
  v_{l,i}^\ast(x)=\max_j \ \genmat_{0,i}\Psi^{l-1}v_j(x)
   = \begin{array}[t]{rl} \displaystyle\max_{\tilde v} & \genmat_{0,i}\tilde v\\ \text{s.t.}& \tilde v\in 
   \Psi^{l-1}\mathcal V(x)\end{array}
\]
%
\begin{rem}
Determining the map $v_{l,i}(x)$ for all admissible $x\in \mathcal X$ in general poses a great classification
challenge. 
%
Notice that in our calculations we can avoid determining the particular vertex $v_{l,i}(x)$ explicitly, it
suffices to determine the vertex determining a supporting hyperplane of $\mathcal X_{k+1}$, i.e.~$v_{l,i}^\ast(x)$. 
%
This can be done by adding all possible inequalities and applying a inequality reduction algorithm.
\end{rem}
%
In closed form the iterates can be expressed as
%
\begin{equation}\label{eq:set:iteration:state:dependent:constraints}
\begin{split}
  \mathcal X_{k+1} =& \mathcal X_k\cap\left(\Psi^{-1}\mathcal X_k \ominus \Psi^{k-1}\mathcal V(\mathcal X_k)\right)
  =\mathcal X_k\cap D_k \\
  =& \bigcap_{0\leq l\leq k+1}\left( \Psi^{-l} \mathcal X_0 \underset{1 \leq i\leq l-1}{\bigominus} 
  \Psi^i \mathcal V(\mathcal X_{l-1})\right).
\end{split}\end{equation}
%
Notice that we do not require $\Psi$ to be invertible, in~\eqref{eq:set:iteration:state:dependent:constraints} 
$\Psi^{-1}\mathcal X_k$ merely denotes the preimage of $\mathcal X_k$ under the linear map $\Psi$.
%
We will use~\eqref{eq:set:iteration:state:dependent:constraints} to prove the finite determinability of
$\mathcal X^\infty$, namely that there exists a finite number $N$ such that $x\in\mathcal X_N$ implies
$\Psi x + v \in\mathcal X_N$ for all $v\in\mathcal V(x)$ and hence $\mathcal X_N$ is robustly positively invariant.
%
\begin{thm}\label{thm:finite:MRPI:set:state:dependable}
Let the state constraint set $\mathcal X$ be contained in a band: $\mathcal X\subseteq B=\{x:\Gamma x\leq{\bf{1}}\wedge 
-\Gamma x\leq{\bf{1}}\}$, let the pair $(\Psi,\Gamma)$ be observable and let $\mathcal V(x)=D\mathcal W(x)$ with 
$\mathcal W(x)$ defined by~\eqref{eq:definition:disturbance:set:explicit}. 
%
Then $\mathcal X_N\subseteq \mathcal X_{N+1}$ for a finite $N$, and hence the MRPI set $\mathcal X^\infty =\mathcal X_N$ 
is a polytope.
\end{thm}
%
%
\begin{proof}
From~\eqref{eq:set:iteration:state:dependent:constraints} it is clear that $\mathcal X^\infty = \emptyset$ 
if $\mathcal X_k =\emptyset$ for any $k\geq 0$.
%
For the remainder of the proof we assume that the MRPI set $\mathcal X^\infty$ is non-empty. 
%
For this we require that $\bigcup_{s\in\mathcal S}\mathcal V(s)$ is bounded on any bounded set 
$\mathcal S\subset\mathbb R^n$.
%
The proof has two main steps: 
%
First we prove that $\mathcal X_p$ is bounded for $p\leq n$ where $n$ is the dimension of the state $x$. 
%
The second step is to prove that in~\eqref{eq:set:iteration:state:dependent:constraints}
the set $D_k$ grows exponentially, i.e. that for any given bounded set $\mathcal C$ there exists
finite $N$ such that $\mathcal C\subseteq D_{N}$. The proof is concluded by setting 
$\mathcal C = \mathcal X_{N}$ and deducing that $\mathcal X^\infty = \mathcal X_N$. 
%
For the first step, notice that observability of $(\Psi,\Gamma)$ is equivalent to the observability matrix 
$\Omega$ having full rank, i.e.\ $\mathrm{rank}(\Omega) = \mathrm{rank}(\begin{bmatrix} \Gamma^T \ \cdots \ 
(\Gamma\Psi^{n-1})^T\end{bmatrix}) = n$.
But  this implies that the set 
%
\[
\mathcal P_{n} = \{x: 
\Omega x\leq{\bf{1}}\wedge-\Omega x\leq{\bf{1}}\} = \bigcap_{0\leq l\leq n-1} \Psi^{-l} B
\]
%
is bounded, and since $\mathcal X_k\subseteq \mathcal P_k$ for all $k$, 
the set $\mathcal X_{n}$ is also bounded.


To see that $D_k$ grows exponentially we denote the spectral radius of $\Psi$ by $\rho$, since $\Psi$ is asymptotically
stable we have $\rho<1$.
%
Let $r_1$ be the radius of the largest ball contained in $\mathcal X_0$ i.e. $\mathcal E(r_1)\subseteq\mathcal X_0$ 
and let $r_2$ be the radius of smallest ball containing $\mathcal V(x)$ for all $x\in\mathcal X_0$.
%
Recall that $\mathcal X_k = \bigcap_{l\leq k} D_l$, where $D_k$ is defined by
%
\begin{equation}
  D_l = \underbrace{\Psi^{-l}\mathcal X_0}_{\mathcal S_1} \ominus 
  \underbrace{\left(\bigoplus_{1\leq i\leq l-1} \Psi^{i}\mathcal V(\mathcal X_{l-1})\right)}_{\mathcal S_2}
\end{equation}
%
We can easily lower bound $\mathcal S_1$ by using $r_1$: $\mathcal S_1 = \Psi^{-l}\mathcal X_0 
\supseteq \Psi^{-l}\mathcal E(r_1) \supseteq \mathcal E(\rho^{-l} r_1)$.
%
Recall that $\mathcal X_l\subseteq\mathcal X_{l-1}$ and therefore $\mathcal X_l\subseteq\mathcal X_0$ for all $l\geq0$.
%
We use this fact to obtain the containment $\mathcal S_2 = \bigoplus_{1\leq i\leq l-1} 
\Psi^{i}\mathcal V(\mathcal X_{l-1})\subseteq \bigoplus_{1\leq i\leq l-1} \Psi^{i}\mathcal V(\mathcal X_0)\subseteq
\bigoplus_{1\leq i\leq l-1} \Psi^{i}\mathcal E(r_2)\subseteq\bigoplus_{1\leq i\leq l-1} \mathcal E(\rho^{i} r_2)\subseteq
\mathcal E(\sum_{1\leq i\leq l-1}\rho^i r_2)\subseteq \mathcal E(\frac{1}{1-\rho} r_2)$.
%
In summary we can state that~$D_l$ consists of the exponentially expanding set~$\mathcal S_1$
subtracted by the set~$\mathcal S_2$ which is bounded, therefore~$D_l$ itself expands exponentially,
that is $D_l\supseteq\mathcal E(\rho^{-l} r_1 - \frac{1}{1-\rho} r_2)$.
%
We have proven that for $p\leq n$ the set iterate~$\mathcal X_p$ is bounded, let $r_3$ denote the smallest 
ball that contains $\mathcal X_p$.
%
We can conclude that for $l$ such that $X_p\subseteq\mathcal E(r_3)\subseteq\mathcal 
E(\rho^{-l} r_1 - \frac{1}{1-\rho} r_2)\subseteq D_l$ holds the set $D_l$ covers
$X_p$, i.e. intersections with $D_l$ will not change $X_l$.
%
We can therefore give an upper bound on the number of iterations necessary for the algorithm
to terminate, it is given by the smallest integer $M$ such that
\begin{equation}\label{bnd:first:lower:bound:on:iteration:count}
  M\geq \frac{1}{\log(\frac{1}{\rho})}\left(\log\left(r_3+\frac{1}{1-\rho}r_2\right)-\log r_1 \right)
\end{equation}
is satisfied.
\end{proof}
%
\begin{rem}
Notice that the constants used in~\eqref{bnd:first:lower:bound:on:iteration:count} are not
convenient to compute, we can however compute bounds on $r_1,\, r_2$ and $r_3$ using 
singular values.
%
For this let $\bar\sigma(\Gamma)$ and $\underline\sigma(\Gamma)$ denote the maximal and the minimal
singular value of~$\Gamma$ respectively.
%
We know that~$\bar\sigma(\Gamma)\norm{x}\geq\norm{\Gamma x}$ and therefore $\bar\sigma(\Gamma)\norm{x}
\leq \sqrt{n}\Rightarrow \norm{\Gamma x}\leq\norm{\bf{1}}=\sqrt{n}$, that $r_1=\frac{\bar\sigma(\Gamma)}{\sqrt{n}}$
follows form standard result for singular values, see e.g.~\cite{Golub:1996}.
%
We use a similar argument to obtain a bound on $r_3$ before deriving a bound on $r_2$:
%
It is easy to see that the radius of the largest ball containing $\mathcal X_p$ can be determined using the maximal
norm of the vertices of $\mathcal P_n$, i.e. $r_3=\max_{i}\norm{x_i}$ where $x_i$ satisfies $\Omega_{\mathscr{A}_i} x_i={\bf{1}}$
and $\Omega_{\bar{\mathscr A}_i}x_i<{\bf{1}}$.
%
From this we can deduce that
%
\begin{multline}
  \sqrt{n}=\norm{\bf{1}}=\norm{\Omega_{\mathscr{A}_i}x_i}\geq\underline\sigma(\Omega_{\mathscr{A}_i})\norm{x_i}\\
  =\underline\sigma(\Gamma_{\mathscr{A}_i}\cdot \text{diag}(I,\Psi,\dots,\Psi^{n-1}))\norm{x_i}\\
  \geq\underline\sigma(\Gamma_{\mathscr{A}_i})\underline\sigma( \text{diag}(I,\Psi,\dots,\Psi^{n-1}))\norm{x_i}\\
  \geq\underline\sigma(\Gamma_{\mathscr{A}_i})\underline\sigma(\Psi)^{n-1}\norm{x_i}\\
  \geq\underline\sigma(\Gamma)\underline\sigma(\Psi)^{n-1}\norm{x_i},
\end{multline}
%
which implies that we can get the upper bound $r_3\leq\frac{\sqrt{n}}{\underline\sigma(\Gamma)
\underline\sigma(\Psi)^{n-1}}$.
%
In order to obtain an estimate on $r_2$ we follow a similar argumentation:
%
\begin{multline}
  \bar\sigma(\bar{\bf{H}})\norm{x}+\norm{{\bf{h}}}
  \geq\bar\sigma(\bar{\bf{H}}_{k^\ast})\norm{x}+\norm{{\bf{h}}_{k^\ast}}\\
  =\max_k\{\bar\sigma(\bar{\bf{H}}_k)\norm{x}+\norm{{\bf{h}}_k}\}
  \geq\norm{\max_k\{\bar{\bf{H}}_{\mathscr{A}_i,k} x + {\bf{h}}_{{\mathscr{A}_i},k}\}}\\ 
  =\norm{{\bf{G}}_{\mathscr{A}_i}v_i} \geq\underline\sigma({\bf{G}}_{\mathscr A_i})\norm{v_i}
  \geq\underline\sigma({\bf{G}})\norm{v_i}.
\end{multline}
%
with $\bar{\bf{H}} = ({\bf{H}}^x + {\bf{H}}^u K)$.
%
Notice that with only the assumptions made in Lemma~\ref{thm:finite:MRPI:set:state:dependable}
we have no way to bound~$\norm{x}$ in order to obtain an upper bound on~$r_2$,
however, if we assume that~$\mathcal X_p$ is not empty we can use the bound on~$\mathcal X_p$, i.e.~$r_3$.
%
This is reasonable since we are interested in the asymptotic behaviour of the set rather than
exact bounds on intermediate iterates, hence $r_2\leq\frac{\bar\sigma(\bar{\bf{H}})r_3+\norm{{\bf{h}}}}
{\underline\sigma({\bf{G}})}$ can be used as an estimate for the asymptotic behaviour of $\mathcal V(x)$
in the iteration.
%
All bounds and estimates on $r_1,\,r_2$ and $r_3$ can be calculated in advance to get an estimate
on how many iterations the described algorithm could require.
\end{rem}
%
%
%
%
%
\section{Example I}\label{sec:example:I}
%
%
\begin{figure}
\centering
\begin{lpic}[scale=0.5]{levitatingBall}
\lbl[tr]{25,3; $m g$}
\lbl[br]{25,25; $c\frac{i^2}{y^2}$}
\lbl[bl]{49,17; $y$}
\lbl[bl]{56,55; $i$}
\end{lpic}
\vspace{-2mm}
\caption{Levitating ball system.}
\label{fig:levitating:ball}
\vspace{-2mm}\end{figure}
%
%
%
This section discusses the calculation of the MRPI set for a linearised, simplified model of the magnetic 
levitation system depicted in figure~\ref{fig:levitating:ball}. 
%
The system dynamics for the ball are given by $m \ddot y = m g - c\frac{i^2}{y^2}$, where $m,g,c,i$ and $y$ 
denote the mass of the ball, the gravitational constant, a constant factor, the current and the distance 
between the coil and the centre of the ball respectively.
%
For illustration purposes we neglect inductive dynamics, using the current $u=i$ as the control input and the position
$y$ and its first derivative $\dot y$ as the states: $x = (y,\dot y)^T$. We find that any equilibrium has 
$\dot{y}=0$ and $u=\sqrt{\frac{gm}{c}} y$ for any positive position $y>0$. 
%
Linearising the nonlinear differential equation $\dot x = f(x,u)$ around an equilibrium point $(\hat x, \hat
u)$ gives the approximate linear model 
%
\begin{equation}
   \Delta\dot{x} = \underbrace{\left(\begin{array}{cc}
  0 & 1 \\ \frac{2c\hat u^2}{m\hat x_1^3} & 0
  \end{array}\right)}_{\frac{\partial f}{\partial x}(\hat x,\hat
      u)}\Delta x 
+ \underbrace{\left(\begin{array}{c}
  0 \\ - \frac{2c\hat u}{m\hat x_1^2}
  \end{array}\right)}_{\frac{\partial f}{\partial u}(\hat x,\hat
      u)}\Delta u
\end{equation}
%
where $\Delta u = u -\hat{u}$ and $\Delta x \approx x-\hat{x}$.
%
We derive the discrete time dynamics with sampling rate $T_s$ using the Euler formula $x^+=x+T_s f(x,u) 
=:\tilde f(x,u)$ giving $\Delta x^+ = A \Delta x + B \Delta u$,
%
\[
A = I+T_s\frac{\partial f}{\partial  x}(\hat
  x,\hat u) , \quad
B = T_s \frac{\partial f}{\partial u}(\hat x,\hat u)
\]
%
Although this system has a control input, the algorithm for computing the MRPI set is applicable since 
we consider the closed loop system under the linear feedback  $u=Kx$, where $K$ satisfies the aforementioned the robust 
Lyapunov condition $V(x)-V((A+BK)x+v)\leq \gamma^2v^Tv$ with $V(x)=x^T P x\geq0$, i.e. $x^TPx - ((A+BK)x+v)^TP(
(A+BK)x+v)\geq x^T(Q+K^TRK)x -\gamma^2 v^Tv$ for a minimum  $\gamma^2$, see e.g.~\cite{Boyd:94}.
%
A representation of additive disturbances acting on the linearised model due to linearisation errors, 
i.e. a system representation $x^+=Ax + Bu + v$ with an additive disturbance $v$, can be obtained using the
Mean Value Theorem (e.g.~\cite{Apostol:1974}).
%
%
\begin{thm}[Mean Value Theorem]\label{thm:mean:value:theorem}
Let $g :  X \rightarrow\mathbb R^m$ be continuously
differentiable, $ X\subset\mathbb R^n$ be open,
and $x \in X$, $h \in\mathbb R^n$ be such that 
$x + th \in X$ for all $t\in [0 ,1]$. Then
\begin{equation}
  g(x+h) = g(x) + \left(\int_0^1 \frac{\partial g}{\partial x}(x+th)dt\right)\cdot h.
\end{equation}
\end{thm}
%
%
Using the Mean Value Theorem and the linearisation around $(\hat{x},\hat{u})$, and defining 
$\tilde{x} = x - \hat{x}$, $\tilde{u} = u - \hat{u}$, we obtain the successor state $x^+ = 
\tilde{f}(\hat{x} + \tilde{x},\hat{u} + \tilde{u})$ as
%
\begin{multline*}
x^+= \tilde f(\hat x, \hat u) 
+ \int_0^1\frac{\partial\tilde f}{\partial x}(\hat x + t\tilde x,
\hat u + t\tilde u) dt \cdot \tilde x  \\
+ \int_0^1\frac{\partial\tilde f}{\partial u}(\hat x + t\tilde x,\hat u+
t\tilde{u}) dt\cdot \tilde{u}
\end{multline*}
%
and hence
%
\begin{multline*}
\tilde x^+ = A\tilde{x} + B \tilde{u} +\Bigl(
\int_0^1\frac{\partial\tilde f}{\partial x}(\hat x + t\tilde x,\hat u
             + t\tilde{u})dt - A \Bigr)\tilde x 
\\ 
+\Bigl(\int_0^1\frac{\partial\tilde f}{\partial u}(\hat x +
  t\tilde x,\hat u + t\tilde{u})dt - B\Bigr)\tilde{u}
\end{multline*}
%
This implies the dynamics
%
\[
\tilde x^+ = A\tilde x+B\tilde{u} + H^x\tilde{x} + H^u \tilde{u}, 
\]
%
where $H^x$ and $H^u$ can be determined by integration. 
%
If $f(x,u)$ is continuously differentiable for all $x\in X$ and $u\in U$, where
$X$, $U$ are compact sets, then we can approximate the values of $H^x \tilde{x}+ H^u \tilde{u}$ 
by a finite convex combination of extremal values, i.e. $H^x \tilde{x}+H^u \tilde{u}\in\conv_k
\{H^x_k \tilde{x} + H^u_k \tilde{u}\}$.
%
Thus we can introduce the element\-wise disturbance bound 
%
\begin{multline}\label{eq:definition:element:wise:constraints:on:nonlinearities}
\mathcal V(\tilde{x},\tilde{u})=\biggl\{v:\min_k\{
H^x_{k,i}\tilde{x}+H^u_{k,i}\tilde{u}\}\leq v_i\,\wedge 
\\ 
v_i \leq \max_k\{H^x_{k,i}\tilde{x}+H^u_{k,i}\tilde{u}\}, \, i =1,\dots,n\biggr\}.
\end{multline}
%
Notice that~\eqref{eq:definition:element:wise:constraints:on:nonlinearities} is of the form~\eqref{eq:definition:PWA:polytopic:set:general}
and the theory introduced earlier applies.
%
The additively perturbed linear system $\tilde x^+ = A\tilde x + B\tilde u + v$ accounts for all nonlinearities 
within $X\times U$ if $v\in\mathcal V(\tilde x,\tilde u)$. 
%
For general nonlinear systems finding the extremal values of $(H^x,H^u)$ is non-trivial.
%
To obtain values for $(H^x_k,H^u_k)$ we sample $X\times U$ and evaluate the integral 
expressions defining $(H^x_k,H^u_k)$ pointwise.
%
This leads to an inner approximation of the linearisation error set, however we can make it as tight as necessary
by increasing the number of samples.
%
For this we use the numerical values for the example of the levitating ball: $T_s=30\,\text{ms}$, $C=1$, 
$m=100\,\text{g}$, $\hat x_1 = 50\,\text{mm}$ and $\mathcal X=\{x:\abs{x_1- \hat x_1}\leq 1\,\text{mm}
\wedge \abs{x_2}\leq 105\,\text{mm}/\text{s}\}$, $\mathcal U=\{u:\abs{ u-\hat u}\leq10\,\text{mA}\}$.
%
Using a total of 25 samples for the computation of $(H^x,H^u)$ we obtain the invariant set shown 
in figure~\ref{fig:MRPI:set:levitating:ball}.
%
The algorithm for computing the MRPI set terminates after 3 iterations.
%
%
\begin{figure}
\centering
\begin{lpic}{invariantSetStateDependant(.65,)}
{\tiny
\lbl[r]{9,94; $0.1$}
\lbl[r]{9,86; $0.08$}
\lbl[r]{9,78; $0.06$}
\lbl[r]{9,70; $0.04$}
\lbl[r]{9,63; $0.02$}
\lbl[r]{9,55; $0$}
\lbl[r]{9,47; $-0.02$}
\lbl[r]{9,39; $-0.04$}
\lbl[r]{9,32; $-0.06$}
\lbl[r]{9,24; $-0.08$}
\lbl[r]{9,16; $-0.1$}
\lbl[t]{11,9; $-6$}
\lbl[t]{30,9; $-4$}
\lbl[t]{48,9; $-2$}
\lbl[t]{67.5,9; $0$}
\lbl[t]{86,9; $2$}
\lbl[t]{104,9; $4$}
\lbl[t]{123,9; $6$}
\lbl{120,3; $\times10^{-3}$}
}
{\small
\lbl{68,3; $\tilde x_1$}
\lbl{0,55,90; $\tilde x_2$}
}
\end{lpic}
\caption{The maximal robust positively invariant set for the levitating ball.}
\label{fig:MRPI:set:levitating:ball}
\vspace{-2mm}\end{figure}
%
%
%
%
\section{Recursive Multi-Parametric Quadratic Programming to Solve Min-Max Programs}\label{sec:recursive:mpQP:via:line:search}


In this section we discuss how multi-parametric quadratic programs (mpQP, see e.g.~\cite{Tondel:2003,Bemporad:2002} 
for elaborate discussions) can be solved efficiently with an active set solver (see e.g.~\cite{Fletcher:2000}).
%
The active set of constraints will be determined by a line-search, we will also deal with \emph{degenerate
constraints}, which can arise during the line-search.
%
\subsection{Solving Recursive Equality Constraint mpQPs}\label{ssec:recursive:mpQP}
%
Assume we want to solve the mpQP
%
\begin{equation}
  J(\phi) = \left\{\begin{array}{rcl}
  \min_\theta& &\frac{1}{2} \theta^T R \theta + r^T\theta + V(\theta)\\
  \text{s.t.}& &C\theta\leq e+ T\phi
  \end{array}\right.
\end{equation}
%
with the positive definite weight $R>0$ and the real parameter $\theta$. 
%
We furthermore assume that the constraints are such that the origin is an interior point for a vanishing parameter
$\phi=0$, i.e. $0\in\{\theta:C\theta< e\}$.
%
Using
%
\begin{equation}
  V(\theta) = \left\{\begin{split}
    \max_x & \;\frac{1}{2} x^T Q x + q^Tx\\
    \text{s.t.} &\; Ax  \leq b +S\theta
  \end{split}\right.
\end{equation}
%
with $Q<0$ and the same assumption on the constraint set as for the minimisation.
%
We want to use an active set solver to obtain the solution for $\phi=\phi^\ast$.
%
For this assume that for some $\phi=\phi_0$ we know the active constraints~$\mathcal A$ and~$\hat{\mathcal A}$,
i.e. the inequalities satisfied with equality $C_{\mathcal A}\theta_0=e_{\mathcal A} + T_{\mathcal A}\phi_0$
and $A_{\hat{\mathcal A}}x_0=b_{\hat{\mathcal A}}+S_{\hat{\mathcal A}}\theta_0$.
%
The set of inactive constraints $\mathcal I$ and $\hat{\mathcal I}$ are such that $C_{\mathcal I}\theta_0<
e_{\mathcal I} + T_{\mathcal I}\phi_0$ and $A_{\hat{\mathcal I}}x_0<b_{\hat{\mathcal I}}+S_{\hat{\mathcal I}}
\theta_0$, the variables~$\theta_0$ and $x_0$ denote the optimal solution to the minimisation and the maximisation
respectively.
%
In order to obtain the optimal solution to the multi-parametric quadratic programs for known
active constraints we consider the primal equality constrained mpQP 
%
\begin{equation}\label{app:mpQP:primal}
  V_{\hat{\mathcal A}}(\theta_0) = \left\{\begin{split}
    \max_x & \;\frac{1}{2} x^T Q x + q^Tx\\
    \text{s.t.} &\; A_{\hat{\mathcal A}}x  = b_{\hat{\mathcal A}} +S_{\hat{\mathcal A}}\theta_0
  \end{split}\right.
\end{equation}
%
we get the Lagrangian
%
\begin{equation}\begin{split}
  L_{\hat{\mathcal A}}(x,\lambda,\theta_0)  &= \frac{1}{2} x^T Q x +q^Tx + \lambda^T\left(A_{\hat{\mathcal A}}x - 
  b_{\hat{\mathcal A}} - S_{\hat{\mathcal A}}\theta_0\right)\\
  &=\frac{1}{2} x^T Q x + \left(q + A_{\hat{\mathcal A}}^T\lambda\right)^Tx 
  -\lambda^T \left(b_{\hat{\mathcal A}} + S_{\hat{\mathcal A}}\theta_0\right)
\end{split}\end{equation}
%
minimising over $x$ we obtain the unconstrained dual mpQP
%
\begin{equation}\label{app:mpQP:dual}
  \min_\lambda -\frac{1}{2}\lambda^T A_{\hat{\mathcal A}} Q^{-1}A_{\hat{\mathcal A}}^T \lambda 
  -(b_{\hat{\mathcal A}} + S_{\hat{\mathcal A}}\theta_0 + A_{\hat{\mathcal A}} Q^{-1}q)^T\lambda
  -\frac{1}{2}q^TQ^{-1}q
\end{equation}
%
To solve~\eqref{app:mpQP:primal} we solve the first order optimality conditions
%
\begin{equation}\label{app:kkt:conditions}
  \begin{array}{ccccccc}
    Q x &+& A^T_{\hat{\mathcal A}}\lambda & = & -q && \\
    A_{\hat{\mathcal A}} x & & & = & b_{\hat{\mathcal A}}& +& S_{\hat{\mathcal A}}\theta_0
  \end{array}
\end{equation}
%
which we can solve explicitly.
%
\begin{thm}\label{lem:mpQP:solution}
The solution of~\eqref{app:kkt:conditions} has the representation
\begin{equation}\label{app:mpQP:solution}
  \begin{split}
    y &= M_\theta \theta_0 + m\\
    \lambda &= N_\theta \theta_0 + N_\beta \beta + n
  \end{split}
\end{equation}
where $N_\beta\neq 0$ only if $A_{\hat{\mathcal A}}$ is not right invertible, in which case 
$A_{\hat{\mathcal A}}^TN_\beta=0$ and the columns of $N_\beta$ span ker$(A_{\hat{\mathcal A}}^T)$.
\end{thm}
%
The matrices $M_\theta$, $N_\theta$, $N_\beta$ and vectors $m$, $n$ are constant and the variable~$\beta$ 
is used to parametrise the solution in the null space of~\eqref{app:kkt:conditions}. 
%
We say (\ref{app:mpQP:primal}) is \emph{degenerate} if $N_\beta\neq 0$.
%
\begin{proof}
If $A_{\hat{\mathcal A}}$ is not right invertible, then we must have rank$(A_{\hat{\mathcal A}})=n_y<n_\lambda$ or
rank$(A_{\hat{\mathcal A}})<\min\{n_y,n_\lambda\}$.
%
For the case that rank$(A_{\hat{\mathcal A}})=n_y$ (i.e.\ $A_{\hat{\mathcal A}}$ has full rank and $n_y<n_\lambda$), 
using the QR-decomposition (see e.g.~\cite{Golub:1996}) of $A_{\hat{\mathcal A}}=(Q_1,Q_2)\cdot(R^T,0)^T$ the solution 
is given by $(m^T,n^T)^T = \Sigma (-q^T,b_{\hat{\mathcal A}}^T)^T$, $(M_\theta^T,N_\theta^T)^T = 
\Sigma (0,S^T_{\hat{\mathcal A}})^T$ and $N_\beta=Q_2$, where 
%
\begin{subequations}\label{seq:sigma}
\begin{equation}\label{eq:sigma:normal}
  \Sigma = \left(\begin{array}{cc}
  0 & R^{-1}Q_1^T \\
  Q_1 R^{-T} & -Q_1R^{-T}WR^{-1}Q_1^T
  \end{array}\right) .
\end{equation}
%
On the other hand if rank$(A_{\hat{\mathcal A}})<\min\{n_y,n_\lambda\}$ (so that $A_{\hat{\mathcal A}}$ is rank deficient), then
%
\begin{equation}\label{eq:sigma:degen}
  \Sigma = \left(\begin{array}{cc}
  W^{-1}-W^{-1}R^T\Delta RW^{-1} & W^{-1}R^{T}\Delta Q_1^{T}\\
  Q_1\Delta R W^{-1} & -Q_1\Delta Q_1^T
  \end{array}\right)
\end{equation}
\end{subequations}
%
with $\Delta = (RW^{-1}R^T)^{-1}$. This concludes the proof.
%
\end{proof}
%
Since the degeneracy variable $\beta$ does not appear in the primal optimiser it does not 
affect the value of~\eqref{app:mpQP:primal}.
%
However, by substituting~\eqref{app:mpQP:solution} into~\eqref{app:mpQP:dual} we find
%
\begin{multline}
  -\frac{1}{2}\underbrace{(N_\theta \theta_0 + N_\beta \beta + n)^T A_{\hat{\mathcal A}} Q^{-1}A^T_{\hat{\mathcal A}} 
  (N_\theta \theta_0 + N_\beta \beta + n)}_{\neq f(\beta)} \\-\underbrace{( 
  b_{\hat{\mathcal A}} + S_{\hat{\mathcal A}}\theta_0 + A_{\hat{\mathcal A}} Q^{-1} q)^T(N_\theta \theta_0 + N_\beta \beta + 
  n)}_{f(\theta_0)+f_c + (b^T_{\hat{\mathcal A}}+\theta^T_0S^T_{\hat{\mathcal A}})N_\beta 
  \beta}
\end{multline}
%
And therefore we have that if
%
\begin{equation}
  (b^T_{\hat{\mathcal A}}+\theta^T_0 S^T_{\hat{\mathcal A}})N_\beta \neq 0
\end{equation}
%
the dual problem is unbounded and can be made arbitrarily large by the choice of $\beta$. 
%
Assume $\theta_0$ is chosen to satisfy 
%
\begin{equation}\label{app:mpQP:compatability:assumption}
  N_\beta^Tb = -N_\beta^TS\theta_0,
\end{equation} 
%
then the dual mpQP has a unique solution and the choice of $\beta$ does not affect either the primal nor the 
dual cost and can be used for any purpose. 
%
For general mpQP condition~\eqref{app:mpQP:compatability:assumption} is a restriction on the set
of parameters for which~\eqref{app:mpQP:primal} has a solution of the form~\eqref{app:mpQP:solution}.
%
In our setup we deal with multi stage min-max programs, so that the parameter is the optimiser 
of a previous optimisation problem and~\eqref{app:mpQP:compatability:assumption} can be ensured. 
%
The constraint introduced for that purpose is called \emph{compatibility constraint}. 


The optimal cost is then given by
%
\begin{equation}\label{app:mpQP:cost:to:go}\begin{split}
  V_{\hat{\mathcal A}}(\theta_0) = &\frac{1}{2}\theta^T_0 M_\theta^T Q M_\theta \theta_0 + \left(m^TQM_\theta + q^TM\right) \theta_0\\ 
  &+\left( \frac{1}{2} m^T Q m + q^T m\right)\\
  =&\frac{1}{2} \theta^T_0 Q_\theta \theta_0 + q^T_\theta \theta_0 + d_\theta,
\end{split}\end{equation}
%
i.e. a quadratic function in the parameter.
%
Next we want to solve
%
\begin{equation}\label{mpQP:second:stage}
  J_{\mathcal A,\hat{\mathcal A}}(\phi_0) = \left\{\begin{array}{rl}
  \min_\theta & \frac{1}{2}\theta^TR\theta + r^T\theta + V_{\hat{\mathcal A}}(\theta)\\
  \text{s.t.} & C_{\mathcal A}\theta = e_{\mathcal A} + T_{\mathcal A} \phi
  \end{array}\right.
\end{equation}
%
where the constraints include the compatibility constraints~\eqref{app:mpQP:compatability:assumption} if necessary. 
%
Since we know, that the optimal cost-to-go $V(\theta)$ has the structure~\eqref{app:mpQP:cost:to:go},
the first order constraints of~\eqref{mpQP:second:stage} reduce to
%
\begin{equation}\label{mpQP:second:stage:conditions}
  \begin{array}{ccccccc}
    (R + Q_\theta)\theta &+& C^T_{{\mathcal A}}\eta & = & -q_\theta-r && \\
    C_{{\mathcal A}} \theta & & & = & e_{{\mathcal A}}& +& T_{{\mathcal A}}\phi_0
  \end{array}
\end{equation}
%
which yields the solution
%
\begin{equation}
  \begin{split}
  \theta_0 &= K_\phi \phi_0 + k\\
  \eta_0 &= O_\phi \phi_0 + O_{\hat\beta} \hat\beta + o
  \end{split}
\end{equation}
%
with the dual variable~$\eta_0$, as long as $R+Q_\theta>0$.

Notice that~\eqref{app:mpQP:compatability:assumption} is only nontrivial if~$A_{\hat{\mathcal A}}$ is degenerate.
%
Since~\eqref{app:mpQP:compatability:assumption} defines a constraint in~\eqref{mpQP:second:stage} it will have a dual
variable~$\zeta$, in order to guarantee continuity of~$\lambda$ we define $\beta=\zeta$.
%
This implies that if $A_{\hat{\mathcal A}}$ is rank deficient the optimal dual variable $\lambda$
depends continuously on~$\phi$.
%
\subsection{Line Search to Update Active Set}\label{ssec:line:search}
%
In order to compute the solution for the parameter~$\phi = \phi^\ast$ we perform a line-search in order
to determine the set of active constraints at $\phi = \phi^\ast$.
%
For this we notice that we have an affine formulation of all optima with respect to~$\phi$, i.e.
%
\begin{equation}\label{mpQP:affine:parameterisation}
  \begin{array}{rcl} 
  \theta(\phi) &=&K_\phi \phi + k\\
  \eta(\phi,\hat \beta) &=& O_\phi \phi + O_{\hat\beta}\hat\beta + o\\
  x(\phi) &=& M_\theta K_\phi \phi + (M_\theta k+ m)\\
  \lambda(\phi, \hat\beta) &=& (N_\theta K_\phi + N_\beta O^\zeta_\phi)\phi + 
  N_\beta O^\zeta_{\hat\beta}\hat\beta\\ & &+ (N_\theta k + N_\beta o^\zeta + n) .
  \end{array}
\end{equation}
%
The dependency on $\hat\beta$ remains if the initial stage~\eqref{mpQP:second:stage} is degenerate.
%
We can use~\eqref{mpQP:affine:parameterisation} to determine the set of active constraints along the line
%
\begin{equation}
  \phi(\alpha) = \phi_0 + \alpha(\phi^\ast-\phi_0)
\end{equation}
%
that means that the first change in the set of active constraints is the one associated with smallest
value~$\alpha^\ast$ to produce an equality in
%
\begin{equation}\label{mpQP:conditions:for:the:line:search}
  \begin{split}
  \eta(\phi(\alpha),0)&\geq0\\
  \lambda(\phi(\alpha),0)&\leq0\\
  C_{\mathcal I}\theta(\phi(\alpha))&\leq e_{\mathcal I} + T_{\mathcal I}\phi(\alpha)\\
  A_{\hat{\mathcal I}}x(\phi(\alpha))&\leq b_{\hat{\mathcal I}}+S_{\hat{\mathcal I}}\theta(\phi(\alpha)).
  \end{split}
\end{equation}
%
After updating the active set $\mathcal A$ and $\hat{\mathcal A}$ accordingly the optimisation sequence~\eqref{app:mpQP:primal}
and~\eqref{mpQP:second:stage} are re-solved and the line search can be performed with updated affine 
parametrisations~\eqref{mpQP:affine:parameterisation} starting the line at~$\phi_0=\phi(\alpha^\ast)$.


Notice that in~\eqref{mpQP:conditions:for:the:line:search} we set $\hat \beta=0$, this is justified in
most cases because the existence of a non-trivial dependence on~$\hat\beta$ implies that $\theta$ is uniquely
defined by the constraints (assuming the constraints are non-redundant), so that $\phi$ is fixed by constraints.
%
\subsection{Degeneracy in Initial Stage}\label{ssec:degeneracy}
%
When the dependence on~$\hat\beta$ is non-trivial two or more constraints on the first minimisation~\eqref{mpQP:second:stage}
are linearly dependent,
% 
i.e. there exists an $i^\ast\in\mathcal A$ such that the solution
to the first optimisation is unchanged if $i^\ast$ is removed from the set of active constraints while all
constraints are still satisfied, that is $J_{\mathcal A\setminus \{i^\ast\},\hat{\mathcal A}}(\phi)=J_{\mathcal A,\hat{\mathcal A}}(\phi)$
while $C_{i^\ast}\theta(\phi)=e_{i^\ast}+T_{i^\ast}\phi$ and $C_{\mathcal I}\theta<e_{\mathcal I}+T_{\mathcal I}\phi$.
%
In order to determine the constraint~$i^\ast$ that can be removed from the active set we look at the dual
problem and its dependence on~$\hat\beta$.
%
\begin{multline}
  J_{\mathcal A,\hat{\mathcal A}}^d(\phi) = \max_\eta -\frac{1}{2} (c_\theta+C^T_{\mathcal A}\eta)^T(R+Q_\theta)^{-1}
  (c_\theta+C^T_{\mathcal A}\eta)\\
  -(e_{\mathcal A}+T_{\mathcal A}\phi)^T \eta+ d_\theta.
\end{multline}
%
From first order conditions~\eqref{mpQP:second:stage:conditions} we know that 
$\eta = O_\phi\phi+O_{\hat\beta}\hat\beta+o$ with~$C^T_{\mathcal A}O_{\hat\beta}=0$, hence we have
%
\begin{equation}\label{mpQP:linesearch:degenerate:constraints:beta}
  J_{\mathcal A,\hat{\mathcal A}}^d(\phi) = \left\{\begin{array}{rcl}
  \max_{\hat\beta}& &\mathcal C(\phi) -(e_{\mathcal A}+T_{\mathcal A} \phi)^TO_{\hat\beta}\hat\beta\\
  \text{s.t.}& &O_\phi\phi+O_{\hat\beta}\hat\beta+o\geq0
  \end{array}\right.
\end{equation}
where $\mathcal C(\phi)$ is a constant which depends only on $\phi$. 
%
Maximisation~\eqref{mpQP:linesearch:degenerate:constraints:beta} is a regular linear program in~$\hat\beta$.


A standard non-degeneracy assumption for active set solvers is that only one constraint is affected at each line-search
iteration, this means that when constraints become degenerate the null-space~$\ker C_{\mathcal A}$ is
one-dimensional, furthermore no additional constraints may be activated since~$\phi$ is already fixed by
the constraints.
%
This implies that~\eqref{mpQP:linesearch:degenerate:constraints:beta} is a scalar linear program, since
$O_{\hat\beta}$ parametrises the null-space of $\ker C_{\mathcal A}$.
%
We conclude that no more than two constraints are candidates to be deactivated in order to remove the degeneracy
of the constraints, namely the ones corresponding to the maximal and minimal $\hat\beta=
-\frac{O_\phi\phi+o}{O_{\hat\beta}}$.
%
After deactivating the constraint corresponding to the maximiser of~\eqref{mpQP:linesearch:degenerate:constraints:beta},
the line-search can be continued without redundancy.


Notice that here we only deal with a single stage problem, that is we have a recursion of one
maximisation and one minimisation, however all methods discussed here translate one-to one-to the
case where more min-max programs are concatenated recursively, as in multi stage min-max control.
%
%
%
%
\section{Solving Min-Max Programs}\label{sec:solving:min:max:programs}

In this section we apply the results derived in the previous section to the considered min-max robust
control problem~\eqref{seq:general:problem:statement}. 
%
For the case that the set of active constraints is known, we define a recursion that provides a 
closed solution for~\eqref{seq:general:problem:statement}.
%
We first express~\eqref{seq:general:problem:statement} in the form
%
\begin{subequations}\label{eq:the:problem:reformulated}%
\begin{equation}
  J_{m}^\ast(x) = \min_u \max_{w,x^+} \tfrac{1}{2}\bigl(\norm{x}_Q^2+\norm{u}_R^2-\gamma^2
    \norm{w}^2\bigr) + J_{m-1}^\ast(x^+)
\end{equation}
%
subject to
%
\begin{gather}
  x^+ = A x + B u + D w
\\
\label{eq:dist:cons}
  G w \leq  H(x,u)
\\
\label{eq:state:constraints}
  {\bf{\Xi}}^x_m x + {\bf{\Xi}}^u_m u \leq {\bf{\xi}}_m
\\
  \hat C_m x^+ = - {\bf{1}}
\\
  C_m^x x + C_m^u u  = {\bf{1}}
\end{gather}
\end{subequations}
%
with~$J_0^\ast(x^+) = \frac{1}{2}\|x^+\|_{P_0}^2$, $m=1,\dots,N$ and $H(x,u)=\max_k\{{\bf{H}}_k^x x + {\bf{H}}_k^u u+ {\bf{h}}_k\}$. 
%
We split the sequence of  min-max problems into a sequence of multi-parametric 
quadratic programs. Starting with the maximisation at stage $m=1$ and using a backward sweep approach
(see e.g.~\cite{Bryson:1975}), this yields
%
\[
  \hat J_m^\ast(x,u) = \left\{\begin{split}
    \max_{w,x^+}\ & {-\frac{\gamma^2}{2}}\norm{w}^2 + J_{m-1}^\ast(x^+)\\
    \text{s.t. }\  & \begin{array}[t]{rcl}
    Gw & \leq & H(x,u)\\
    x^+ & = & Ax + Bu + Dw\\
    \hat C_m x^+ &=& -{\bf{1}}
    \end{array}
    \end{split}\right.
\]
%
and
%
\[
  J_m^\ast(x) = \left\{\begin{split}
    \min_{u}\ & \frac{1}{2}\left(\norm{x}^2_Q + \norm{u}_R^2\right) + \hat J_m^\ast(x,u)\\
    \text{s.t.}\ & \begin{array}[t]{ccccl}
    {\bf{\Xi}}^x_m x &+& {\bf{\Xi}}^u_m u &\leq &{\bf{\xi}}_m\\
    C_m^x x &+ & C^u_m u & = & {\bf{1}}
    \end{array}
    \end{split}
    \right.
\]
%
Suppose the active set is given, i.e.~it is known which inequality constraints hold with equality. 
%
For notational convenience we denote active inequalities with $(\cdot)^\prime$ in this section rather than 
$(\cdot)_{\mathcal A_m}$, e.g.  $({\bf{\Xi}}^x_m)^\prime x + ({\bf{\Xi}}^u_m)^\prime u = {\bf{\xi}}_m^\prime$. 
%
Given that $J^\ast_0(x^+) = \frac{1}{2}\|x^+\|_{P_0}^2$, compatibility constraints are not necessary at 
stage $m=1$ and the maximisation problem is given by:
%
\[
  \hat J_1^\ast(x,u) = \left\{\begin{split}
  \max_{w,x^+} \ & {-\frac{\gamma^2}{2}}\norm{w}^2 + J_{0}^\ast(x^+)\\
  \text{s.t. }\ & 
  \underbrace{\left(\begin{array}{cc}
  G^\prime & 0 \\ -D & I
  \end{array}\right)}_{\bar H}
  \left(\begin{array}{c}w\\ x^+\end{array}\right)
  \\&= \underbrace{\left(\begin{array}{cc}W_1^x & W_1^u \\ A & B\end{array}\right)}_{
  \bar S
  }
  \left(\begin{array}{c}x \\ u \end{array}\right) + \underbrace{\left(\begin{array}{c}
  w_1^c \\ 0\end{array}\right)}_{\bar f}
  \end{split}\right.
\]
%
with $W_m^x = ({\bf{H}}_{{\bf{k}}_m^\ast}^x)^\prime, W_m^u = ({\bf{H}}_{{\bf{k}}_m^\ast}^u)^\prime $ 
and $w_m^c = ({\bf{h}}_{{\bf{k}}_m^\ast})^\prime$ denoting the active affine terms of the right hand side 
of~\eqref{eq:dist:cons} at stage~$m$.
%
Using the results discussed in the previous section we obtain
%
\[
      \left(\begin{array}{c}
      w^\ast \\
      x^{+,\ast} \\
      \eta^\ast \\
      \lambda^\ast
      \end{array}\right) = \left(\begin{array}{c}M^w_z\\ M^{x^+}_z \\ N^{\eta}_z \\ N^{\lambda}_z
      \end{array}\right)\underbrace{\left(\begin{array}{c}x\\ u\end{array}\right)}_z + 
      \left(\begin{array}{c}0\\ 0 \\ N^{\eta}_{\hat\beta} \\ N^{\lambda}_{\hat\beta}
      \end{array}\right)\hat\beta + \left(\begin{array}{c}m^w\\ m^{x^+} \\ n^{\eta} \\ n^{\lambda}
      \end{array}\right)
\]
%
where $\eta^\ast$ denotes the dual variable to the active inequality constraints and hence must
be non-negative, i.e.~$\eta^\ast\geq0$. 
%
Notice that to avoid overloaded notation we have omitted the stage indices.
%
The cost-to-go for the minimisation problem at stage $m=1$ is
%
\[
  \hat J_1^\ast(z) = \frac{1}{2}z^T
    \hat Q_1 z + c_1 z + d_1
\]
%
and the compatibility constraint is given by
%
\begin{equation}\label{prototype:compatibility:conditions}
  N_{\hat\beta}^T(\bar S z + \bar f) = 0,
\end{equation}
%
i.e. $C_1^x$ and $C_1^u$ enforce a row wise normalised version of~\eqref{prototype:compatibility:conditions}.
%
Hence the minimisation problem at $m=1$ becomes
%
\[
  J_1^\ast(x) = \left\{\begin{split}
  \min_{u} \ & \frac{1}{2}\left(\norm{x}^2_Q + \norm{u}_R^2\right) + \hat J_{1}^\ast(x,u)\\
    \text{s.t.} \ & 
    \underbrace{\left(\begin{array}{c}
    ({\bf{\Xi}}_1^u)^\prime \\ C_1^u
    \end{array}\right)}_{\bar C}
    u
    = \underbrace{\left(\begin{array}{c}-({\bf{\Xi}}^x_1)^\prime \\ -C_1^x\end{array}\right)}_{
    \bar T
    }x + 
    \underbrace{\left(\begin{array}{c}{\bf{\xi}}_1^\prime\\  {\bf{1}} \end{array}\right)}_{\bar e}
    \end{split}\right.
\]
%
and its solution is given by
%
\[
  \left(\begin{array}{c}
  u^\ast \\
  \nu^\ast \\
  \hat\zeta^\ast
  \end{array}\right) = \left(\begin{array}{c}K^u_x\\ L^{\nu}_x \\ L^{\hat\zeta}_x
  \end{array}\right)x + 
  \left(\begin{array}{c}0\\ L^{\nu}_\beta \\ L^{\hat\zeta}_{\beta}
  \end{array}\right)\beta + \left(\begin{array}{c}k^u\\ l^{\nu} \\ l^{\hat\zeta}
  \end{array}\right).
\]
%
For completeness the $m=2$ maximisation and its solution are given as
%
\begin{gather*}
  \hat J_2^\ast(x,u) = \left\{\begin{split}
  \max_{w,x^+} \ & {-\frac{\gamma^2}{2}}\norm{w}^2 + J_{1}^\ast(x^+)\\
  \text{s.t. }\ & 
  \underbrace{\left(\begin{array}{cc}
  G^\prime & 0 \\ -D & I \\
  0 & \hat C_2
  \end{array}\right)}_{\bar A}
  \left(\begin{array}{c}w\\ x^+\end{array}\right)
  \\&= \underbrace{\left(\begin{array}{cc}W_m^x & W_m^u \\ A & B \\ 0 & 0\end{array}\right)}_{
  \bar S
  }
  \left(\begin{array}{c}x \\ u \end{array}\right) + \underbrace{\left(\begin{array}{c}
  w_m^c \\ 0 \\ {\bf{1}}\end{array}\right)}_{\bar b}
  \end{split}\right.
\\
  \left(\begin{array}{c}
  w^\ast \\
  x^{+,\ast} \\
  \eta^\ast \\
  \lambda^\ast\\
  \zeta^\ast
  \end{array}\right) = \left(\begin{array}{c}M^w_z\\ M^{x^+}_z \\ N^{\eta}_z \\ N^{\lambda}_z \\ N^{\zeta}_z
  \end{array}\right)z + 
  \left(\begin{array}{c}0\\ 0 \\ N^{\eta}_{\hat\beta} \\ N^{\lambda}_{\hat\beta} \\ N^\zeta_{\hat\beta}
  \end{array}\right)\hat\beta + \left(\begin{array}{c}m^w\\ m^{x^+} \\ n^{\eta} \\ n^{\lambda}\\ n^\zeta
  \end{array}\right)
\end{gather*}
%
where $\hat C_2 x = {\bf{1}}$ is a normalised version of $L^T_\beta(\bar T x + \bar e) = 0$.
All subsequent minimisations and maximisations can be solved analogously provided the active set is
known.
%
\subsection{Line Search with Piecewise Affine Disturbance Set}
%
In order to solve the multi-stage problem for a given system state~$x^\ast$ we perform a line search
form a known active set~${\bar{\mathcal A}} = \{\mathcal A_N,\hat {\mathcal A}_N,\dots,\hat{\mathcal A}_1\}$
as described in section~\ref{ssec:line:search}.
%
To determine the active right hand side of~\eqref{eq:dist:cons}, i.e. ${\bf{k}}^\ast_m$, we use a similar line 
search based approach.
%
In the sequel of this section we assume that the origin is an interior point of the disturbance set for vanishing
states and inputs, i.e.~$0<H(0,0)$ which implies $b_{{\bf{k}}^\ast}>0$ at the origin, this is important in order to guarantee
the non-degeneracy of the problem, at the origin $x=0$ no constraints are active.
%
We use the affine representation of the optimal state and input at stage $k$ with respect to the initial 
state~$x_N$ denoted by $x_m = \Psi_m^x x_N + \psi_m^x$ and $u_k = \Psi_m^u x_N + \psi_m^u$ respectively.
%
Performing a line search along $x_N$ we can reduce $H(x_m(\alpha),u_m(\alpha))$ to 
%
\[
\begin{split}
  H_i(x_m(\alpha),u_m(\alpha)) &= \begin{aligned}[t] \max_j\{ & \left(H^x_{i,j} \Psi^x_m
          +H^u_{i,j}\Psi^u_m\right)x_N(\alpha)\\
        & + \left(H^x_{i,j} \psi^x_m +H^u_{i,j}\psi^u_m + h_{i,j}\right) \}
        \end{aligned}\\
  &=\max_j f_j\alpha + g_j
  \end{split}
\]
%
which we can rewrite as
%
\begin{equation}\label{eq:definition:as:mpLP}
  H_i(x_m(\alpha),u_m(\alpha)) = \left\{\begin{array}{rcl} \min_{(t,\alpha)}& &t\\
  \text{s.t.}& &f_j\alpha+g_j \leq t\; \forall j.\\
  & &0\leq\alpha\leq1
  \end{array}\right.
\end{equation}
%
Thus the elementwise determination of the active affine representation is a multi-parametric linear program
(see e.g.~\cite{Gal:1995}) that has to be solved in every active set update in order to provide the active solution.
%
This can be done by computing the vertices of $\mathcal H = \{(t,\alpha):0\leq\alpha\leq1\wedge f_j\alpha+g_j
\leq t\;\forall j\}$ and ordering the vertices such that $0=\alpha_1\leq\alpha_2\leq\dots$ the solution that 
has to be considered in the line search is then given by the one corresponding to $\alpha_2$.
%
The active indices of the right hand side~${\bf{k}}^\ast_m$ can be included in the list of active indices~$\bar{\mathcal A}=\{
\mathcal A_N,(\hat{\mathcal A}_N,{\bf{k}}^\ast_N),\dots,\mathcal A_1,(\hat{\mathcal A}_1,{\bf{k}}^\ast_1)\}$.
%
Notice that although $\bar{\mathcal A}$ needs to be updated by performing the line search discussed in 
section~\ref{ssec:line:search} and solving the scalar mpLP~\eqref{eq:definition:as:mpLP}, the recursion solving
equality constrained mpQPs discussed in section~\eqref{ssec:recursive:mpQP} does not need to be performed when
some~${\bf{k}}^\ast_m$ changes for an inactive constraint, i.e. only when $W_m^x$, $W_m^u$ and $w_m^c$ change the
recursion has to be solved again.
%
Since the solution to the min-max problem is obtained recursively an update of $\hat{\mathcal A}_m$ only
affects the solution to mpQPs at higher stages, i.e. $J_m^\ast$ and all $\hat J_i^\ast$, $J_i^\ast$ have to be
solved for $m< i\leq N$. 
%
This allows us to reduce the computational workload carried out online. 
%
In the next section the complexity of the presented algorithm is discussed.
%
%
%
\section{Complexity}\label{sec:complexity}
%
For a given active set~$\bar{\mathcal A}$ at most $2N$ mpQPs must be solved, and this is done by decomposing the
problem as stated in section~\ref{sec:solving:min:max:programs}. 
%
For each mpQP the main computational effort is to determine $\Sigma$ in~\eqref{seq:sigma}. 
%
In the case of~\eqref{eq:sigma:normal} this requires a QR
decomposition with $2(mn^2-n^3/3)$ floating point operations (flops, see e.g.~\cite{Golub:1996}), 
where $m$ is the number of active constraints and $n$ the number of
optimisation variables, plus inversion of a triangular matrix with $(m^3-m)/6$ flops and several matrix
multiplications with $mpn$ flops (for the multiplication of a $m\times n$ matrix with a $n\times p$
matrix). 
%
The computationally more expensive case of~\eqref{eq:sigma:degen} requires a QR decomposition,
inversion of a definite matrix $W$ using Cholesky decomposition with $n^3/3$ flops, inversion of a triangular
matrix, several matrix multiplications and additions with $mn$ flops, and inversion of a definite matrix
$\Delta$. 
%
In the worst case this adds up to at most $11n^3+n^2-n/3$ flops to obtain $\Sigma$. 
%
The solution to
the problem is then the result of a matrix multiplication, and, in order to be able to solve the subsequent
mpQP, the matrix $W_\theta$ and the vector $c_\theta$ also need to be computed. Hence the overall flop count
in the worst case adds up to $11n^3+n^2+2/3n+2n^2 n_\theta$, where $n_\theta$ denotes the dimension of the
parameter~$\theta$. 
%
In the worst case the
recursion for the entire horizon therefore requires $N(2 n_x+5 n_x^2+101 n_x^3+8 n_x^2 (n_u+n_x))$ flops.

The number of active set changes needed to obtain the active set corresponding to the current plant state
is necessarily finite, since this number cannot exceed the total number of possible active sets. 
%
However upper bounds on this number are unrealistically large (except in pathological cases) and hence of 
little use in bounding the number of times that the recursion of Section~\ref{sec:recursive:mpQP:via:line:search} 
needs to be solved. 
%
Instead we give the typical execution time for an example system with an implementation in MATLAB  in 
section~\ref{sec:example:II}.
%


\section{Example II}\label{sec:example:II}

Using the levitating ball system introduced in section~\ref{sec:example:I} we calculate stage wise state constraints
and solve the recursive min-max problem.
%
We perform a cold started line search from $x_a=(0,0)$ to the outer bound of the constraint set at $x_e=(1,-30)$, 
the resulting trajectories at the boundaries of individual active sets are plotted in Figure~\ref{fig:plot}.
%
The weights chosen for this experiment are~$Q=\text{diag}(2,1)$, $R=1$ and $\gamma^2=1175$.
%
The simulation was implemented in MATLAB using only non-optimised built-in functions for the main computational
purposes. 
%
In the simulation illustrated in Fig.~\ref{fig:plot} a total of $10$ iterations were required,
of which $7$ correspond to changes of the dominating right hand side of $\mathcal W(x,u)$, for which no
recomputation of the solution is necessary.
%
For $x_e$ on the boundary of the feasible set the solution time is less than $0.5\, \text{s}$ in total 
(using a MacBook Pro with a $2.3\,\text{GHz}$ quad-core processor).
%
Figure~\ref{fig:computation:times} illustrates the dependency of the computation times on the horizon length~$N$.

\begin{figure}
\centering
\includegraphics[width=\columnwidth]{myplot}
\caption{Projected stage constraints $\mathcal X_i, i=1,\dots,N$ in red. Trajectories
at the active set changes and on the boundary in blue.}
\label{fig:plot}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=\columnwidth]{ComputationTimes.pdf}
\caption{The \textcolor[rgb]{0,0,1}{blue points} show the overall computation time from a cold start 
at~$x_a=(0,0)$ to the boundary of the feasible set. The \textcolor[rgb]{0,.6,0}{green points} show the slowest recursion
performed which approximately is linear.}
\label{fig:computation:times}
\end{figure}


% needed in second column of first page if using \IEEEpubid
%\IEEEpubidadjcol


% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.




\section{Conclusion}\label{sec:conclusion}
The conclusion goes here.




% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%


\appendices


% use section* for acknowledgment
\section*{Acknowledgment}


The authors would like to thank...


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{IEEEabrv,MyLib}

%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
% \begin{thebibliography}{1}

% \end{thebibliography}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{face.pdf}}]{Rainer Manuel Schaich}
Biography text here.
\end{IEEEbiography}

% if you will not have a photo at all:
\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{face.pdf}}]{Mark Cannon}
Biography text here.
\end{IEEEbiography}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


